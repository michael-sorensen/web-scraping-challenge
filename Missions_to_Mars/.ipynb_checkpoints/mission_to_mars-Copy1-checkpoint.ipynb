{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "\n",
    "* Scrape the [Mars News Site](https://redplanetscience.com/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splinter\n",
    "executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit( \"https://redplanetscience.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "news_title = soup.find('div', class_='content_title').get_text()\n",
    "news_p = soup.find('div', class_='article_teaser_body').get_text()\n",
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for the Featured Space Image site [here](https://spaceimages-mars.com).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "featured_image_url = 'https://spaceimages-mars.com/image/featured/mars2.jpg'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "img_url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(img_url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html,'html.parser')\n",
    "img_slug = soup.find('img', class_='headerimage fade-in')['src']\n",
    "featured_image_url = (f'{img_url}{img_slug}')\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape facts table\n",
    "facts_url = \"https://galaxyfacts-mars.com/\"\n",
    "facts_table = pd.read_html(facts_url, attrs = {'class': 'table-striped'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df = facts_table[0]\n",
    "facts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facts_html = facts_df.to_html()\n",
    "print(facts_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "\n",
    "* Visit the astrogeology site [here](https://marshemispheres.com/) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [/Users/michaelsorensen/.wdm/drivers/chromedriver/mac64/94.0.4606.61/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "imgs_url = 'https://marshemispheres.com/'\n",
    "browser.visit(imgs_url)\n",
    "time.sleep(2)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://marshemispheres.com/cerberus.html',\n",
       " 'https://marshemispheres.com/schiaparelli.html',\n",
       " 'https://marshemispheres.com/syrtis.html',\n",
       " 'https://marshemispheres.com/valles.html']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = soup.find_all('div',class_='item')\n",
    "urls = []\n",
    "\n",
    "for page in pages:\n",
    "    url = f\"{imgs_url}{page.a['href']}\"\n",
    "    urls.append(url)\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "title_img = {}\n",
    "for url in urls:\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    title_div = soup.findAll('div',attrs={\"class\":\"cover\"})\n",
    "    for x in title_div:\n",
    "        title = x.find('h2').text\n",
    "        title_img['title'] = title\n",
    "    img = browser.links.find_by_partial_href('enhanced.tif')\n",
    "    img = img['href']\n",
    "    title_img = {}\n",
    "    title_img['img_url'] = img\n",
    "    hemisphere_image_urls.append(title_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img_url': 'https://marshemispheres.com/images/cerberus_enhanced.tif',\n",
       "  'title': 'Cerberus Hemisphere Enhanced'},\n",
       " {'img_url': 'https://marshemispheres.com/images/schiaparelli_enhanced.tif',\n",
       "  'title': 'Schiaparelli Hemisphere Enhanced'},\n",
       " {'img_url': 'https://marshemispheres.com/images/syrtis_major_enhanced.tif',\n",
       "  'title': 'Syrtis Major Hemisphere Enhanced'},\n",
       " {'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced.tif'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - MongoDB and Flask Application\n",
    "\n",
    "Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "* Start by converting your Jupyter notebook into a Python script called `scrape_mars.py` with a function called `scrape` that will execute all of your scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "* Next, create a route called `/scrape` that will import your `scrape_mars.py` script and call your `scrape` function.\n",
    "\n",
    "  * Store the return value in Mongo as a Python dictionary.\n",
    "\n",
    "* Create a root route `/` that will query your Mongo database and pass the mars data into an HTML template to display the data.\n",
    "\n",
    "* Create a template HTML file called `index.html` that will take the mars data dictionary and display all of the data in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel free to create your own design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def scraper():\n",
    "    \n",
    "    # Splinter\n",
    "    executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "    browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "    \n",
    "    # Create dictionary\n",
    "    mars_dictionary = {}\n",
    "\n",
    "    # NASA Mars News\n",
    "    browser.visit( \"https://redplanetscience.com/\")\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    news_title = soup.find('div', class_='content_title').get_text()\n",
    "    news_p = soup.find('div', class_='article_teaser_body').get_text()\n",
    "    \n",
    "    \n",
    "    # JPL Mars Space Images\n",
    "    img_url = 'https://spaceimages-mars.com/'\n",
    "    browser.visit(img_url)\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = bs(html,'html.parser')\n",
    "    img_slug = soup.find('img', class_='headerimage fade-in')['src']\n",
    "    featured_image_url = (f'{img_url}{img_slug}')\n",
    "    featured_image_url\n",
    "    \n",
    "    # Mars Facts\n",
    "    facts_url = \"https://galaxyfacts-mars.com/\"\n",
    "    facts_table = pd.read_html(facts_url, attrs = {'class': 'table-striped'})\n",
    "    facts_df = facts_table[0]\n",
    "    facts_html = facts_df.to_html()\n",
    "\n",
    "    #Mars Hemispheres\n",
    "    executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "    browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "    imgs_url = 'https://marshemispheres.com/'\n",
    "    browser.visit(imgs_url)\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    pages = soup.find_all('div',class_='item')\n",
    "    urls = []\n",
    "\n",
    "    for page in pages:\n",
    "        url = f\"{imgs_url}{page.a['href']}\"\n",
    "        urls.append(url)\n",
    "\n",
    "    urls\n",
    "\n",
    "    for page in pages:\n",
    "        url = f\"{imgs_url}{page.a['href']}\"\n",
    "        urls.append(url)\n",
    "        \n",
    "        \n",
    "    hemisphere_image_urls = []\n",
    "    title_img = {}\n",
    "    for url in urls:\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        browser.visit(url)\n",
    "        time.sleep(2)\n",
    "        title_div = soup.findAll('div',attrs={\"class\":\"cover\"})\n",
    "        for x in title_div:\n",
    "            title = x.find('h2').text\n",
    "            title_img['title'] = title\n",
    "        img = browser.links.find_by_partial_href('enhanced.tif')\n",
    "        img = img['href']\n",
    "        title_img = {}\n",
    "        title_img['img_url'] = img\n",
    "        hemisphere_image_urls.append(title_img)\n",
    "        \n",
    "        \n",
    "    mars_dictionary = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_p\": news_p,\n",
    "        \"featured_image_url\": featured_image_url,\n",
    "        \"fact_table\": facts_html,\n",
    "        \"hemisphere_images\": hemisphere_image_urls\n",
    "    }\n",
    "\n",
    "    browser.quit()\n",
    "    return mars_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [/Users/michaelsorensen/.wdm/drivers/chromedriver/mac64/94.0.4606.61/chromedriver] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [/Users/michaelsorensen/.wdm/drivers/chromedriver/mac64/94.0.4606.61/chromedriver] found in cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper()\n",
    "mars_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
